# ğŸ¬ Traductor SRT - OpenAI & Deepseek

Traductor de subtÃ­tulos `.srt` con soporte para **OpenAI** y **Deepseek**, con interfaz web en tiempo real usando Flask.

## âœ¨ CaracterÃ­sticas

- ğŸ¤– **MÃºltiples proveedores de IA**: OpenAI (GPT-4, GPT-3.5, etc.) y Deepseek
- ğŸ“Š **TraducciÃ³n con contexto global**: Genera resumen de la pelÃ­cula/serie para traducciones mÃ¡s precisas
- âš¡ **Streaming en tiempo real**: Ve los logs en vivo mientras se traduce
- ğŸ“ˆ **Barra de progreso**: Seguimiento de progreso durante la traducciÃ³n
- ğŸ’¾ **Historial de traducciones**: Descarga archivos traducidos anteriormente
- ğŸ¨ **Interfaz moderna**: UI responsiva y oscura
- ğŸ³ **Docker**: Desplegable en cualquier lado

## ğŸš€ Inicio RÃ¡pido

### Requisitos

- Docker y Docker Compose
- Cuenta en OpenAI y/o Deepseek con API keys vÃ¡lidas

### InstalaciÃ³n

1. Clona el repositorio:
```bash
git clone https://github.com/sergiogarciaj/traductor.git
cd traductor
```

2. Crea un archivo `.env` con tus claves:
```bash
cp .env.example .env
```

3. Edita `.env` y agrega tus API keys:
```
OPENAI_API_KEY=sk-...
DEEPSEEK_API_KEY=sk-...
```

4. Levanta los contenedores:
```bash
docker-compose up --build
```

5. Abre en tu navegador: **http://localhost:5000**

## ğŸ“– Uso

1. **Selecciona proveedor**: OpenAI o Deepseek
2. **Elige modelo**: Los modelos se filtran segÃºn el proveedor
3. **Carga archivo `.srt`**: Tu archivo de subtÃ­tulos
4. **Selecciona idioma destino**: EspaÃ±ol, PortuguÃ©s, FrancÃ©s, AlemÃ¡n, Italiano
5. **Elige estrategia**:
   - **Contexto global** (recomendado): Genera resumen de la pelÃ­cula/serie
   - **Por bloques**: Traduce sin contexto (mÃ¡s econÃ³mico)
6. **Traduce**: El archivo se descarga automÃ¡ticamente

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno (`.env`)

```env
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-3.5-turbo

# Deepseek
DEEPSEEK_API_KEY=sk-...

# Docker (opcional)
WORKERS=1
THREADS=4
TIMEOUT=600
```

### Modelos Disponibles

**OpenAI:**
- GPT-5.1 (mejor calidad)
- GPT-5-mini
- GPT-5-nano
- GPT-4o
- GPT-4o-mini
- GPT-4-turbo
- GPT-3.5-turbo

**Deepseek:**
- deepseek-chat
- deepseek-coder
- deepseek-reasoner

## ğŸ“ Estructura

```
traductor/
â”œâ”€â”€ app.py                 # AplicaciÃ³n Flask principal
â”œâ”€â”€ Dockerfile             # ConfiguraciÃ³n Docker
â”œâ”€â”€ docker-compose.yml     # OrquestaciÃ³n de contenedores
â”œâ”€â”€ requirements.txt       # Dependencias Python
â”œâ”€â”€ .env.example          # Template de variables de entorno
â”œâ”€â”€ .gitignore            # Git ignore
â””â”€â”€ README.md             # Este archivo
```

## ğŸŒŸ CaracterÃ­sticas TÃ©cnicas

### Backend (Python/Flask)
- Procesamiento de SRT con anÃ¡lisis inteligente
- Soporte para mÃºltiples proveedores de IA
- Logs en tiempo real vÃ­a Server-Sent Events (SSE)
- Progreso en vivo con polling
- Normalizador de mayÃºsculas
- CachÃ© de glosarios entre chunks

### Frontend (HTML/CSS/JavaScript)
- Interfaz responsiva
- Selector dinÃ¡mico de modelos
- Streaming de logs
- Timer en tiempo real
- Descarga automÃ¡tica
- Historial de traducciones

## ğŸ› Troubleshooting

### "No hay OPENAI_API_KEY"
- Verifica que tu `.env` estÃ© en la raÃ­z del proyecto
- AsegÃºrate de que `docker-compose.yml` tiene acceso al `.env`
- Reconstruye: `docker-compose down && docker-compose up --build`

### Los logs no aparecen
- Usa 1 worker en Gunicorn (ya configurado por defecto)
- Verifica que tu navegador no bloquea EventSource

### TraducciÃ³n muy lenta
- Prueba con "Por bloques" para ahorrar tokens
- Usa un modelo mÃ¡s rÃ¡pido (ej: GPT-3.5-turbo, deepseek-chat)

## ğŸ“ Licencia

MIT

## ğŸ‘¤ Autor

Sergio GarcÃ­a - [@sergiogarciaj](https://github.com/sergiogarciaj)

## ğŸ™ Agradecimientos

- OpenAI por la API de GPT
- Deepseek por su API compatible
- Flask por el framework web
- Gunicorn por el servidor

---

â­ Si te Ãºtil, dÃ©jame una estrella en GitHub
